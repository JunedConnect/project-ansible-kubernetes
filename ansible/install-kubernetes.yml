#initial working playbook to install kubernetes, this is has been succeded by the Ansible Roles which have been configured to be more idempodent
---
- name: prerequisites
  hosts: tag_ansible_kubernetes
  become: true

  tasks:

  - name: Disable Swap
    ansible.builtin.shell: swapoff -a


  - name: Change hostname
    ansible.builtin.hostname:
      name: "{{ inventory_hostname }}"
    
  - name: Apt Upgrade
    ansible.builtin.apt:
      update_cache: true
      upgrade: full

  - name: Enable IP Forwarding
    ansible.builtin.shell: |
      cat <<EOF | tee /etc/sysctl.d/k8s.conf
      net.ipv4.ip_forward = 1
      EOF

      sysctl --system


- name: install-containerd
  hosts: tag_ansible_kubernetes
  become: true

  tasks:

  - name: Install Package
    ansible.builtin.apt:
      name: containerd
      state: present

  - name: Configure containerd
    ansible.builtin.shell: |
      mkdir -p /etc/containerd
      containerd config default | tee /etc/containerd/config.toml
      sed -i 's/SystemdCgroup = false/SystemdCgroup = true/g' /etc/containerd/config.toml
      systemctl restart containerd


- name: install-kubernetes
  hosts: tag_ansible_kubernetes
  become: true

  tasks:

  - name: Install Packages
    ansible.builtin.apt:
      name:
        - apt-transport-https
        - ca-certificates
        - curl
        - gpg
      state: present

  - name: Download Google Cloud Public Signing Key
                                                      # make version into variable
    ansible.builtin.shell: curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.35/deb/Release.key | gpg --yes --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg

  - name: Add Kubernetes Apt Repository
    ansible.builtin.shell: echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.35/deb/ /' | tee /etc/apt/sources.list.d/kubernetes.list

  - name: Apt Update
    ansible.builtin.apt:
      update_cache: true

  - name: Install Kubernetes Components
    ansible.builtin.apt:
      name:
        - kubelet=1.35.0-1.1 # make into variable
        - kubeadm=1.35.0-1.1 # make into variable
        - kubectl=1.35.0-1.1 # make into variable
      state: present

  - name: Hold Kubernetes Packages
    ansible.builtin.dpkg_selections:
      name: "{{ item }}"
      selection: hold
    loop:
      - kubelet
      - kubeadm
      - kubectl


- name: initialise-kubeadm
  hosts: tag_control_plane
  become: true

  tasks:

  - name: Initialise Kubeadm
    ansible.builtin.shell: kubeadm init
    args:
      creates: /etc/kubernetes/admin.conf

  - name: Create Kube Config Directory
    ansible.builtin.file:
      path: /home/ubuntu/.kube
      state: directory
      owner: ubuntu # make into a variable
      group: ubuntu # make into a variable
      mode: 755

  - name: Copy Admin Kube Config to User Kube Config
    ansible.builtin.copy:
      src: /etc/kubernetes/admin.conf
      dest: /home/ubuntu/.kube/config
      owner: ubuntu # make into a variable
      group: ubuntu # make into a variable
      remote_src: true
  
  - name: Retrieve Worker Node Join Command
    shell: kubeadm token create --print-join-command
    register: worker_node_join_command # this will allow the use of the output for workers to be able to join

  - name: set join command
    set_fact:
      worker_node_join_command: "{{ worker_node_join_command.stdout }}"
    delegate_to: localhost
    delegate_facts: True


- name: join-workers-to-cluster
  hosts: tag_worker_node
  become: true

  tasks:

  - name: Join Worker Node to Control Plane # here is a link to where I had found out how to useputs of previous tasks, and use them in other tasks : https://devops.stackexchange.com/questions/18911/how-to-pass-the-result-from-one-task-on-one-host-to-another-task-on-another-h
    ansible.builtin.shell: "{{ hostvars['localhost']['worker_node_join_command'] }}>> node_joined.txt"
    args:
      chdir: $HOME
      creates: node_joined.txt


- name: install-cilium
  hosts: tag_control_plane
  become: true

  tasks:

  - name: Download Cilium
    ansible.builtin.shell: | # make version into variable
      CILIUM_CLI_VERSION=$(curl -s https://raw.githubusercontent.com/cilium/cilium-cli/main/stable.txt)
      CLI_ARCH=amd64
      if [ "$(uname -m)" = "aarch64" ]; then CLI_ARCH=arm64; fi
      curl -L --fail --remote-name-all https://github.com/cilium/cilium-cli/releases/download/${CILIUM_CLI_VERSION}/cilium-linux-${CLI_ARCH}.tar.gz{,.sha256sum}
      sha256sum --check cilium-linux-${CLI_ARCH}.tar.gz.sha256sum
      tar xzvfC cilium-linux-${CLI_ARCH}.tar.gz /usr/local/bin
      rm cilium-linux-${CLI_ARCH}.tar.gz cilium-linux-${CLI_ARCH}.tar.gz.sha256sum

  - name: Check Cilium version
    ansible.builtin.shell: cilium version
    register: cilium_version

  - name: Install Cilium
    ansible.builtin.shell: cilium install --version v1.18.3 --set-string ipam.operator.clusterPoolIPv4PodCIDRList=20.0.0.0/8
    when: "'cilium image (running): unknown. Unable to obtain cilium version. Reason: release: not found' in cilium_version.stdout"